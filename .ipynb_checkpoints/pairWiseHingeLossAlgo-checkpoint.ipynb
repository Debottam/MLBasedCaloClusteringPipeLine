{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c40c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from collections import namedtuple, defaultdict\n",
    "import open3d as o3d\n",
    "import random\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b377ad",
   "metadata": {},
   "source": [
    "## Opening files containing features in pairs of cells from same cluster (+ve e.g.) and different cluster (-ve e.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040e7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_pair = h5py.File(\"./pair_set.hdf5\", 'r')\n",
    "hf_nopair = h5py.File(\"./nopair_set.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207778da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = hf_pair.get('pair')[:]\n",
    "nopair = hf_nopair.get('nopair')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc79ea9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3f78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_pair.close()\n",
    "hf_nopair.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344bc784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 2, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b552cd00",
   "metadata": {},
   "source": [
    "## Concatenating +ve and -ve examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a364e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = np.concatenate((pair,nopair),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b77813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af218752",
   "metadata": {},
   "source": [
    "## Making labels 1 for +ve e.g and -1 for -ve e.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcad52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_label = np.concatenate(([1]*500000,[-1]*500000),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aead390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e03535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff920245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56252339, 0.39402719, 0.16334734, 0.26086957, 0.        ,\n",
       "        1.        , 0.89405496, 1.        , 0.0011919 , 0.77126392],\n",
       "       [0.55990222, 0.39252812, 0.16334734, 0.26086957, 0.        ,\n",
       "        0.97567125, 0.87601607, 1.        , 0.0011919 , 0.77126392]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408583a1",
   "metadata": {},
   "source": [
    "## Randomizing data and dividing into train, test parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b63afb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1000000)\n",
    "np.random.shuffle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "020d62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset_rand = total_dataset[arr]\n",
    "total_label_rand =  total_label[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dde465d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, truth_label_train, truth_label_test = train_test_split(\n",
    "    total_dataset_rand, total_label_rand, train_size=0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2334e95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 2, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d42fa2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_label_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b433481d",
   "metadata": {},
   "source": [
    "### Making Pytorch specific dataset and Network and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8647a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset for pairwise training\n",
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pair = (self.data[index][0], self.data[index][1])\n",
    "        label = torch.tensor(self.labels[index], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            pair = (self.transform(pair[0]), self.transform(pair[1]))\n",
    "\n",
    "        return pair, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07220fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "pairs = [(torch.Tensor(pair[0]), torch.Tensor(pair[1])) for pair in features_train]\n",
    "labels = torch.tensor(truth_label_train, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ded63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3faf977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Define the architecture for one branch of the Siamese network\n",
    "        self.branch = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        # Forward pass for one branch of the Siamese network\n",
    "        return self.branch(x)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Forward pass for both branches of the Siamese network\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c407d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise hinge loss function\n",
    "class PairwiseHingeLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(PairwiseHingeLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, target):\n",
    "        # Compute the pairwise hinge loss\n",
    "        distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss = torch.mean(torch.clamp(self.margin + distance - target * self.margin, min=0))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3c45d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10  # Adjust this based on your input data size\n",
    "hidden_size = 64  # You can customize this based on your task\n",
    "\n",
    "# Create a Siamese network\n",
    "siamese_net = SiameseNetwork(input_size, hidden_size)\n",
    "\n",
    "# Create a pairwise hinge loss criterion\n",
    "criterion = PairwiseHingeLoss()\n",
    "\n",
    "# Set up data loaders\n",
    "#transform = transforms.Compose([transforms.ToTensor()])\n",
    "#dataset = SiameseDataset(data=pairs, labels=labels, transform=transform)\n",
    "dataset = SiameseDataset(data=pairs, labels=labels)\n",
    "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8841c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SiameseDataset at 0x1869af430>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4a9953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer\n",
    "optimizer = optim.Adam(siamese_net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68ce6423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k8/cklb1sxj1p35mft4gbkymsc091k_dc/T/ipykernel_62776/98518432.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[index], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0230\n",
      "Epoch [2/20], Loss: 1.0526\n",
      "Epoch [3/20], Loss: 0.9375\n",
      "Epoch [4/20], Loss: 1.0033\n",
      "Epoch [5/20], Loss: 1.0263\n",
      "Epoch [6/20], Loss: 0.9967\n",
      "Epoch [7/20], Loss: 1.0592\n",
      "Epoch [8/20], Loss: 0.9770\n",
      "Epoch [9/20], Loss: 0.9901\n",
      "Epoch [10/20], Loss: 1.0493\n",
      "Epoch [11/20], Loss: 1.0658\n",
      "Epoch [12/20], Loss: 0.9934\n",
      "Epoch [13/20], Loss: 0.9836\n",
      "Epoch [14/20], Loss: 1.0822\n",
      "Epoch [15/20], Loss: 1.0099\n",
      "Epoch [16/20], Loss: 0.9770\n",
      "Epoch [17/20], Loss: 0.9671\n",
      "Epoch [18/20], Loss: 0.9803\n",
      "Epoch [19/20], Loss: 0.9836\n",
      "Epoch [20/20], Loss: 1.0526\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        inputs, target = batch\n",
    "        input1, input2 = inputs\n",
    "\n",
    "        # Forward pass\n",
    "        output1, output2 = siamese_net(input1, input2)\n",
    "        loss = criterion(output1, output2, target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea2870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
